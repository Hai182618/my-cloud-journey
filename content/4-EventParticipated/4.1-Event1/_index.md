---
title: "Event Participation – AI/ML/GenAI on AWS"
date: "2025-11-15"
weight: 1
chapter: false
pre: "<b>1.</b>"
---

## Event 1 – AI/ML/GenAI on WORKSHOP

## Event Information
**Date & Time:** Saturday, November 15, 2025, 8:30 AM – 12:00 PM  
**Location:** AWS Vietnam Office  
**Role:** Attendee

---

## Event Purpose
The workshop was designed to provide hands-on experience with AWS AI/ML services, focusing on Amazon SageMaker for traditional machine learning workflows and Amazon Bedrock for generative AI applications. The event aimed to help participants understand the practical implementation of AI/ML solutions on AWS and explore the latest capabilities in generative AI.

---

## Agenda Overview

### **8:30 – 9:00 AM | Welcome & Introduction**
- Participant registration and networking opportunities  
- Workshop overview and learning objectives presentation  
- Ice-breaker activity to foster collaboration  
- Overview of the AI/ML landscape in Vietnam  

---

### **9:00 – 10:30 AM | AWS AI/ML Services Overview**
## **Amazon SageMaker – End-to-End ML Platform**

### **Data Preparation and Labeling**
Understanding how to prepare datasets for machine learning, including data cleaning, feature engineering, and automated labeling capabilities.

### **Model Training, Tuning, and Deployment**
Exploring SageMaker’s training infrastructure, hyperparameter tuning, and model deployment options including real-time and batch inference.

### **Integrated MLOps Capabilities**
Learning about SageMaker’s built-in MLOps features for model versioning, monitoring, and automated retraining pipelines.

---

### **Live Demo: SageMaker Studio Walkthrough**
The demonstration showcased the unified development environment for machine learning, including:

- Jupyter notebook integration for interactive development  
- Experiment tracking and model registry  
- Visual workflow builder for MLOps pipelines  
- Integration with other AWS services for data processing  

---

### **10:30 – 10:45 AM | Coffee Break**
Networking session with refreshments and informal discussions about AI/ML use cases.

---

## **10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock**

### **Foundation Models: Claude, Llama, Titan – Comparison & Selection Guide**
- Understanding different foundation models available on Bedrock  
- Comparison of model capabilities, use cases, and performance characteristics  
- Best practices for selecting the right model for specific business needs  
- Cost considerations and optimization strategies  

---

### **Prompt Engineering: Techniques, Chain-of-Thought Reasoning, Few-shot Learning**
- Prompt Engineering Fundamentals: Learning how to craft effective prompts  
- Chain-of-Thought Reasoning: Guiding models through step-by-step reasoning  
- Few-shot Learning: Improving model performance without fine-tuning  

---

## **Retrieval-Augmented Generation (RAG): Architecture & Knowledge Base Integration**
- RAG Architecture Overview: Combining information retrieval with generative AI  
- Knowledge Base Integration: Connecting Bedrock with Amazon OpenSearch, Amazon Kendra, or vector databases  
- Implementation Patterns: Building accurate, context-aware RAG applications  

---

## **Bedrock Agents: Multi-step Workflows and Tool Integrations**
- Agent Architecture: Understanding multi-step workflow orchestration  
- Tool Integration: Connecting agents with APIs, databases, and AWS services  
- Workflow Design: Patterns for agent-based applications  

---

## **Guardrails: Safety and Content Filtering**
- Content Safety: How Bedrock Guardrails filter harmful or inappropriate content  
- Custom Policies: Creating business-specific safety filters  
- Compliance & Governance: Ensuring applications meet ethical and regulatory standards  

---

## **Live Demo: Building a Generative AI Chatbot using Bedrock**
The demonstration walked through creating a complete chatbot application:

1. Setting up the Bedrock foundation model  
2. Implementing RAG with knowledge base integration  
3. Configuring Bedrock Agents for multi-turn conversations  
4. Adding Guardrails for content safety  
5. Deploying the chatbot application  

---

# Key Highlights
- **Comprehensive ML Platform:** SageMaker offers an end-to-end ML workflow  
- **Generative AI Capabilities:** Bedrock provides multiple high-quality foundation models  
- **RAG Architecture:** Enables accurate and knowledge-grounded AI responses  
- **Production-Ready MLOps:** Simplifies deployment and maintenance of ML systems  
- **Safety First:** Guardrails ensure compliance and safe AI interactions  

---

# Key Learnings
- SageMaker Studio boosts productivity with a unified ML interface  
- Foundation model selection must align with use cases and cost constraints  
- Prompt engineering greatly improves model effectiveness  
- RAG is crucial for applications requiring accurate and up-to-date information  
- Bedrock Agents support multi-step, logic-driven AI workflows  
- Safety and compliance must be prioritized early  

---

# Application to My Work
- **Experiment with SageMaker:** Use SageMaker Studio for developing ML models  
- **Build RAG Applications:** Implement RAG for internal documentation and Q&A  
- **Prompt Engineering Practice:** Develop templates and best practices  
- **MLOps Integration:** Automate training and deployment pipelines  
- **Safety Implementation:** Use Bedrock Guardrails in GenAI applications  

---

# Personal Experience
This workshop provided an excellent hands-on introduction to AWS AI/ML services:

- The SageMaker Studio demo highlighted how a unified platform streamlines ML workflows  
- Learning about RAG revealed how to build AI systems that leverage specific knowledge  
- The Bedrock Agents demo showcased the ability to build complex, automated workflows  
- Prompt engineering exercises were immediately useful  
- Understanding Guardrails reinforced the importance of safety in AI  

---

# Takeaways
- Start with clear use cases before choosing technology  
- Foundation models are powerful and reduce development effort  
- RAG is essential for knowledge-based AI applications  
- MLOps is key for maintaining production ML systems  
- Safety cannot be ignored  
- Continuous learning is vital in the fast-evolving AI/ML field  

---

# Event Photos

![Photo ](D:/_____________________TRUYEN/CloudRead-main/CloudRead-main/CloudRead-main/fcj-workshop-template-main/fcj-workshop-template-main/static/images/4-Events%20Participated/1.png)

![Photo ](D:/_____________________TRUYEN/CloudRead-main/CloudRead-main/CloudRead-main/fcj-workshop-template-main/fcj-workshop-template-main/static/images/4-Events%20Participated/2.png)


![Photo ](D:/_____________________TRUYEN/CloudRead-main/CloudRead-main/CloudRead-main/fcj-workshop-template-main/fcj-workshop-template-main/static/images/4-Events%20Participated/3.png)

![Photo ](D:/_____________________TRUYEN/CloudRead-main/CloudRead-main/CloudRead-main/fcj-workshop-template-main/fcj-workshop-template-main/static/images/4-Events%20Participated/4.png)


![Photo ](D:/_____________________TRUYEN/CloudRead-main/CloudRead-main/CloudRead-main/fcj-workshop-template-main/fcj-workshop-template-main/static/images/4-Events%20Participated/5.png)